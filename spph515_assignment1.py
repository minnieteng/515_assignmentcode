# -*- coding: utf-8 -*-
"""SPPH515_Assignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HOwp9wiBOnEzO_CA_QBX0FvLpMLWZ-ow
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# Load the dataset
file_path = '/content/drive/MyDrive/IPD dataset.csv'
df_original = pd.read_csv(file_path)
df = pd.read_csv(file_path)

# Display basic information about the dataset
df.info(), df.head()

# Dimension
df.shape

#subtypes of IPD cases
num_unique_subtypes = df['Serotype'].nunique()

# Display the count of unique IPD subtypes
print(num_unique_subtypes)

#generate missing table

# Replace NA, empty strings, spaces, 'U', and 'Unknown' with 'missing'
df = df.applymap(lambda x: 'missing' if pd.isna(x) or str(x).strip() in ['', 'U', 'Unknown'] else x)

# Count and percentage of missing values for each variable
missing_counts = (df == 'missing').sum()
missing_percentages = ((df == 'missing').mean() * 100).round(2)

# Create a summary table
summary_table = pd.DataFrame({
    'Missing Count': missing_counts,
    'Missing Percentage (%)': missing_percentages
})

# Display the summary table
print(summary_table)

"""#

#Identify Duplicates#
"""

# Identify duplicate records
duplicates = df[df.duplicated(keep=False)]

# Count of duplicate records
num_duplicates = duplicates.shape[0]

# Remove duplicates
df_unique = df.drop_duplicates()

# Number of duplicates removed
duplicates_removed = df.shape[0] - df_unique.shape[0]

duplicates_removed, df_unique.shape

#The dataset contains only unique records, so no duplicates were removed.

"""#Identify errors#"""

# Check for out-of-range ages
out_of_range_age = df_unique[(df_unique['Age'] < 0) | (df_unique['Age'] > 110)]

# Check for invalid gender values
invalid_gender = df_unique[df_unique['Gender'].isin(['U'])]

# Check for outlier years outside 2000-2020
outlier_year_case = df_unique[(df_unique['Year'] < 2000) | (df_unique['Year'] > 2020)]
outlier_year_case

# Record the errors
errors_summary_updated = {
    "Out of range age": len(out_of_range_age),
    "Invalid gender (U)": len(invalid_gender),
    "Outlier year of case": len(outlier_year_case),
    "Total errors identified": len(out_of_range_age) + len(invalid_gender) + len(outlier_year_case)
}

# Display identified errors
errors_details = {
    "Out of Range Age": out_of_range_age,
    "Invalid Gender": invalid_gender,
    "Outlier Year of Case": outlier_year_case
}

for error_type, df in errors_details.items():
    if not df.empty:
        print(f"\n{error_type} Errors:")
        print(df)

errors_summary_updated

# Combine the indices of all error types
error_indices = set(out_of_range_age.index).union(
    invalid_gender.index,
    outlier_year_case.index
)

# Remove the error records from the dataset
df_cleaned = df_unique.drop(index=error_indices)
print(df_cleaned.columns.tolist())

df_cleaned.shape

"""#Identify Structural Issues#"""

# Convert 'Episode Date' to datetime format
df_cleaned['Episode Date'] = pd.to_datetime(df_cleaned['Episode Date'], errors='coerce')

# Now identify the mismatched record
mismatched_year_corrected = df_cleaned[
    (df_cleaned['Episode Date'].notnull()) &
    (df_cleaned['Year'] != df_cleaned['Episode Date'].dt.year)
]

# Display mismatched records
print(mismatched_year_corrected)

# Remove the mismatched record
df_cleaned = df_cleaned.drop(index=mismatched_year_corrected.index)

# Display the updated dataset shape
df_cleaned.shape

df_cleaned.to_csv('df_cleaned.csv', index=False)
df_cleaned.shape

"""#Fix missing data#"""

# Identify missing values, including NaN, empty strings, spaces, 'Unknown', and 'Pending'
missing_values = (df.isna() | (df == "") | (df == " ") | (df == "Unknown") | (df == "Pending")).sum()

# Convert to a DataFrame with missing percentages
missing_table = pd.DataFrame({
    'Variable': missing_values.index,
    'Missing_Percentage': (missing_values / len(df)) * 100
})

# Display the missing table
print(missing_table)

df_cleaned.shape

#drop serotype column (feature drop)
df_cleaned = df_cleaned.drop(columns=['Serotype'])

# Display the updated dataset shape to confirm
df_cleaned.shape

#check rows that have missing data
# Calculate the number of missing values per row
missing_counts = df_cleaned.isnull().sum(axis=1)

# Set the threshold for 40% missing values
threshold_40_percent = df_cleaned.shape[1] * 0.1

# Filter rows with more than 40% missing values
rows_with_40_percent_missing = df_cleaned[missing_counts > threshold_40_percent]

rows_with_40_percent_missing

#no rows with >40% missing values

"""#Descriptive analyses#

##by person
"""

# Tabulate the number of IPD cases by Gender
gender_counts = df_cleaned['Gender'].value_counts()

# Calculate percentage of cases by Gender
gender_percentages = (gender_counts / gender_counts.sum()) * 100

# Display the counts and percentages
print("IPD Cases by Gender:")
print(gender_counts)
print("\nPercentage of IPD Cases by Gender:")
print(gender_percentages)

# Define 5-year age groups
bins = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, 69, 74, 79, 84, float('inf')]
labels = ['0-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39',
          '40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74',
          '75-79', '80-84', '85+']

# Create age group column
df_cleaned['Age Group'] = pd.cut(df_cleaned['Age'], bins=bins, labels=labels, right=True)

# Count cases by Age Group
age_group_counts = df_cleaned['Age Group'].value_counts().sort_index()

# Plot the number of IPD cases by Age Group
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
age_group_counts.plot(kind='bar')
plt.xlabel('5-Year Age Groups')
plt.ylabel('Number of IPD Cases')
plt.title('IPD Cases by 5-Year Age Groups')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

df_cleaned.columns

# Identify the 5-year age group with the fewest and most cases
fewest_cases_group = age_group_counts.idxmin()
most_cases_group = age_group_counts.idxmax()

print(f"Age Group with Fewest Cases: {fewest_cases_group} ({age_group_counts.min()} cases)")
print(f"Age Group with Most Cases: {most_cases_group} ({age_group_counts.max()} cases)")

"""##by place"""

# Group by Health Authority (HA) and Health Service Delivery Area (HSDA)
ha_hsda_counts = df_cleaned.groupby(['HA', 'HSDA']).size().reset_index(name='IPD Cases')

# Display the counts
print(ha_hsda_counts)

# Identify the HA with the most and fewest total IPD cases
ha_totals = ha_hsda_counts.groupby('HA')['IPD Cases'].sum().reset_index()

most_cases_ha = ha_totals.loc[ha_totals['IPD Cases'].idxmax()]
fewest_cases_ha = ha_totals.loc[ha_totals['IPD Cases'].idxmin()]

# Identify HSDA with the most and fewest IPD cases
most_cases_hsda = ha_hsda_counts.loc[ha_hsda_counts['IPD Cases'].idxmax()]
fewest_cases_hsda = ha_hsda_counts.loc[ha_hsda_counts['IPD Cases'].idxmin()]

# Display results
print(f"HA with the Most IPD Cases: {most_cases_ha['HA']} ({most_cases_ha['IPD Cases']} cases)")
print(f"HA with the Fewest IPD Cases: {fewest_cases_ha['HA']} ({fewest_cases_ha['IPD Cases']} cases)")

print(f"HSDA with the Most IPD Cases: {most_cases_hsda['HA']} - {most_cases_hsda['HSDA']} ({most_cases_hsda['IPD Cases']} cases)")
print(f"HSDA with the Fewest IPD Cases: {fewest_cases_hsda['HA']} - {fewest_cases_hsda['HSDA']} ({fewest_cases_hsda['IPD Cases']} cases)")

ha_hsda_counts = df_cleaned

# Grouping by Health Authority (HA) and HSDA to count the number of IPD cases
ha_hsda_counts_grouped = ha_hsda_counts.groupby(['HA', 'HSDA']).size().reset_index(name='IPD Cases')

# Pivoting the data for stacked bar plot
ha_hsda_pivot = ha_hsda_counts_grouped.pivot(index='HA', columns='HSDA', values='IPD Cases').fillna(0)

# Plotting the stacked bar plot with counts
ax = ha_hsda_pivot.plot(kind='bar', stacked=True, figsize=(14, 8), colormap='tab20')

# Adding case counts to each bar segment
for container in ax.containers:
    for bar in container:
        height = bar.get_height()
        if height > 0:
            ax.text(
                bar.get_x() + bar.get_width() / 2,   # Center the text horizontally
                bar.get_y() + height / 2,            # Center the text vertically within the bar segment
                f'{int(height)}',                    # Convert height to an integer for display
                ha='center', va='center', fontsize=9, color='black'  # Formatting the text
            )

# Customizing the plot
plt.xlabel('Health Authority (HA)')
plt.ylabel('Number of IPD Cases')
plt.title('Stacked Bar Plot of IPD Cases by Health Authority (HA) and HSDA')
plt.xticks(rotation=45)
plt.legend(title='HSDA', bbox_to_anchor=(1.05, 1), loc='upper left')

# Adjust layout to prevent overlap
plt.tight_layout()

# Display the plot
plt.show()

"""## by time"""

# Group by Year to count IPD cases
yearly_cases = df_cleaned.groupby('Year').size().reset_index(name='IPD Cases')

# Plotting the number of IPD cases by Year
plt.figure(figsize=(12, 6))
sns.lineplot(data=yearly_cases, x='Year', y='IPD Cases', marker='o', color='orange')

# Customize the plot
plt.xlabel('Year')
plt.ylabel('Number of IPD Cases')
plt.title('IPD Cases by Year in BC')
plt.grid(True)  # Add gridlines for better readability

plt.tight_layout()  # Adjust layout to prevent overlapping
plt.show()

# Ensure 'Episode Date' is in datetime format
df_cleaned['Episode Date'] = pd.to_datetime(df_cleaned['Episode Date'], errors='coerce')

# Extract the week number and year from the 'Episode Date'
df_cleaned['Week Number'] = df_cleaned['Episode Date'].dt.isocalendar().week
df_cleaned['Year'] = df_cleaned['Episode Date'].dt.year

# Identify the earliest case of IPD for each year
earliest_case_per_year = df_cleaned.groupby('Year')['Week Number'].min().reset_index()

# Plotting the earliest week number by year
plt.figure(figsize=(12, 6))
sns.lineplot(data=earliest_case_per_year, x='Year', y='Week Number', marker='o', color='orange')

# Customize the plot
plt.xlabel('Year')
plt.ylabel('Week Number of Earliest IPD Case')
plt.title('Earliest IPD Case (by Week Number) for Each Year in BC')
plt.grid(True)

plt.tight_layout()
plt.show()

"""## by person and time"""



#import population size data by HSDA
filepath = '/content/drive/MyDrive/Population sizes by HSDA.csv'
population_data = pd.read_csv(filepath)

# Merge the cleaned IPD dataset with the population dataset
merged_data = pd.merge(
    df_cleaned,
    population_data,
    how='left',
    left_on=['HA', 'HSDA', 'Year'],
    right_on=['HA', 'HSDA', 'Year']
)

# Display the first few rows of the merged dataset
print(merged_data.head())

# Step 1: Calculate IPD incidence rates per 100,000 population
# Grouping the data by Year, AgeGroup, and Sex
incidence_data = merged_data.groupby(['Year', 'AgeGroup', 'Sex']).agg(
    Cases=('ID', 'count'),
    Population=('Population', 'sum')
).reset_index()

# Calculate incidence rate per 100,000
incidence_data['Incidence Rate (per 100,000)'] = (incidence_data['Cases'] / incidence_data['Population']) * 100000

# Step 2: Plotting

import matplotlib.pyplot as plt
import seaborn as sns

# Plot 1: IPD Incidence Rates by Year, Age Group, and Sex
plt.figure(figsize=(14, 8))
sns.lineplot(data=incidence_data, x='Year', y='Incidence Rate (per 100,000)', hue='Sex', style='AgeGroup', markers=True, dashes=False)

plt.title('IPD Incidence Rates (per 100,000) by Year, Age Group, and Sex')
plt.xlabel('Year')
plt.ylabel('Incidence Rate (per 100,000)')
plt.legend(title='Sex & Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# Plot 2: Number of IPD Cases by Year
cases_per_year = merged_data.groupby('Year')['ID'].count().reset_index(name='Number of Cases')

plt.figure(figsize=(12, 6))
sns.barplot(data=cases_per_year, x='Year', y='Number of Cases', color='skyblue')

plt.title('Number of IPD Cases Reported by Year')
plt.xlabel('Year')
plt.ylabel('Number of Cases')
plt.grid(axis='y')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.ticker as ticker

# Step 1: Prepare Data
# Count of cases per year
cases_per_year = merged_data.groupby('Year')['ID'].count().reset_index(name='Number of Cases')

# Mapping age group codes to descriptive labels
age_group_labels = {
    'a00_04': '0-4 years',
    'a05_16': '5-16 years',
    'a17_64': '17-64 years',
    'a65+': '65+ years'
}

# Average incidence rate per year, age group, and sex
age_sex_rates = incidence_data.groupby(['Year', 'AgeGroup', 'Sex'])['Incidence Rate (per 100,000)'].mean().reset_index()

# Step 2: Plotting with Dual Axes
fig, ax1 = plt.subplots(figsize=(14, 8))

# Bar Plot: Number of IPD Cases (Primary Y-axis)
ax1.bar(cases_per_year['Year'], cases_per_year['Number of Cases'], color='skyblue', label='Number of Cases')
ax1.set_xlabel('Year')
ax1.set_ylabel('Number of Cases', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')
ax1.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))  # Ensure integer x-axis

# Line Plot: Age-Standardized Incidence Rates (Secondary Y-axis)
ax2 = ax1.twinx()

# Plot age-standardized rates for each age group and sex
for (age_group, sex), group_data in age_sex_rates.groupby(['AgeGroup', 'Sex']):
    label = f'{age_group_labels.get(age_group, age_group)} - {sex}'
    ax2.plot(
        group_data['Year'],
        group_data['Incidence Rate (per 100,000)'],
        marker='o',               # Add markers for clarity
        linestyle='--',           # Dashed lines for distinction
        linewidth=2,              # Thicker lines for visibility
        label=label  # Legend label
    )

# Axis Labels for Secondary Y-axis
ax2.set_ylabel('Incidence Rate (per 100,000)', color='green')
ax2.tick_params(axis='y', labelcolor='green')

# Step 3: Final Customizations
plt.title('IPD Cases and Age-Standardized Incidence Rates by Year, Age Group, and Sex in BC')
ax1.grid(True)  # Add gridlines for readability

# Legends for Both Axes
lines_labels = [ax.get_legend_handles_labels() for ax in [ax1, ax2]]
lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]
ax1.legend(lines, labels, bbox_to_anchor=(1.05, 1), loc='upper left')  # Position legend outside plot

# Adjust Layout
plt.tight_layout()
plt.show()

"""##By place and time

"""

ipd_cases = pd.read_csv('/content/drive/MyDrive/df_cleaned (1).csv')
population_hsda = pd.read_csv('/content/drive/MyDrive/Population sizes by HSDA.csv')

# Standardize HSDA names to ensure consistency
ipd_cases['HSDA'] = ipd_cases['HSDA'].str.strip().str.replace('/', '-', regex=False)
population_hsda['HSDA'] = population_hsda['HSDA'].str.strip().str.replace('/', '-', regex=False)

# Correct known discrepancies in HSDA naming
ipd_cases['HSDA'] = ipd_cases['HSDA'].replace({'North Shore-Coast Garibal': 'North Shore-Coast Garibaldi'})

# Aggregate population data by HSDA and Year to get total population sizes
population_aggregated = population_hsda.groupby(['HSDA', 'Year'])['Population'].sum().reset_index()

# Merge the IPD case dataset with the aggregated population data
merged_data = pd.merge(ipd_cases, population_aggregated, how='left', on=['HSDA', 'Year'])

# Exclude 'Out of Prov' from the analysis
merged_data = merged_data[merged_data['HSDA'] != 'Out of Prov']

# 1) Count the number of cases per HSDA
case_counts = merged_data.groupby('HSDA').size().reset_index(name='Case_Count')

# 2) Calculate the crude rate per 100,000 population
# First, get the total population per HSDA
population_per_hsda = merged_data.groupby('HSDA')['Population'].sum().reset_index()

# Merge case counts with population data
crude_rate_data = pd.merge(case_counts, population_per_hsda, on='HSDA')

# Calculate the crude rate per 100,000 population
crude_rate_data['Crude_Rate_per_100k'] = (crude_rate_data['Case_Count'] / crude_rate_data['Population']) * 100000

crude_rate_data

# Prepare the data: Calculate crude rates by HSDA and Year
crude_rate_by_year = merged_data.groupby(['HSDA', 'Year']).agg(
    Case_Count=('ID', 'size'),
    Population=('Population', 'sum')
).reset_index()

# Calculate the crude rate per 100,000 population
crude_rate_by_year['Crude_Rate_per_100k'] = (crude_rate_by_year['Case_Count'] / crude_rate_by_year['Population']) * 100000

# Exclude 'Out of Prov' again for plotting
crude_rate_by_year = crude_rate_by_year[crude_rate_by_year['HSDA'] != 'Out of Prov']

# Create facet plots for crude IPD case rates by HSDA, by year with labels every two years
g = sns.FacetGrid(crude_rate_by_year, col="HSDA", col_wrap=4, height=4, sharey=False)
g.map_dataframe(sns.lineplot, x="Year", y="Crude_Rate_per_100k", marker="o")

# Adjust plot labels and titles
g.set_titles("{col_name}")
g.set_axis_labels("Year", "Crude Rate per 100,000")

# Label every two years
years = sorted(crude_rate_by_year['Year'].unique())
every_two_years = [year for i, year in enumerate(years) if i % 2 == 0]

for ax in g.axes.flatten():
    ax.set_xticks(every_two_years)
    ax.set_xticklabels(every_two_years, rotation=45)

plt.tight_layout()
plt.show()

